<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Multilayer FDR control with e-values | Daniel C. Posmik</title> <meta name="author" content="Daniel C. Posmik"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://posmikdc.github.io/projects/multilayer_fdr/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Daniel </span>C. Posmik</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/repositories/">Repositories</a> <a class="dropdown-item" href="/teaching/">Teaching</a> <a class="dropdown-item" href="/Users/posmikdc/Documents/assets/cv/cv.pdf">CV</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Multilayer FDR control with e-values</h1> <p class="post-description"></p> </header> <article> <h2 id="introduction">Introduction</h2> <p>Sometimes we want to test hypotheses within groups or partitions, i.e. testing the effect of multiple drugs with many patients in each drug-specific cohort. In literature, there are well-established methods to control false discovery rates (FDR) in groups, i.e. the group-weighted Benjamini-Hochberg (weighted BH) procedure (see, <a href="https://academic.oup.com/biostatistics/article/18/1/91/2555340" rel="external nofollow noopener" target="_blank">Benjamini &amp; Cohen, 2017</a>). Now, a key weakness of this procedure is its invalidity when the independence assumption is violated. In practice, the independence assumption is usually strong. Thus, we are curious to explore FDR control within partitions under dependence scenarios.</p> <p>For this project, we consider e-values as an alternative to p-values since e-values allow for dependence (see, <a href="https://academic.oup.com/jrsssb/article/84/3/822/7056146" rel="external nofollow noopener" target="_blank">Wang &amp; Ramdas, 2022</a>). Specifically, we shall discuss e-values, their applications, transformations, and finally an e-filter adaptation to the p-filter procedure proposed in <a href="https://arxiv.org/abs/1703.06222" rel="external nofollow noopener" target="_blank">Ramdas et al, 2019</a> (The p-filter allows for multi-layer FDR control for grouped hypotheses).</p> <p><a href="https://academic.oup.com/jrsssb/article/84/3/822/7056146" rel="external nofollow noopener" target="_blank">Wang &amp; Ramdas, 2022</a> propose an interesting example in Section 8, aiming to detect cryptocurrencies with a positive return. We take inspiration from this example, but in the interest of time and conciseness, modify their example in several meaningful ways. First, we do not have access to the data, so we simulate year-to-year rate of change in stock price (see details below). Next, we do not consider this example in an investment setting, i.e. we set their investment parameter \(\lambda\) equal to 1. That means that we hold constant our investment and thus interested in identifying which coins seem promising in what year.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/multilayer_fdr-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/multilayer_fdr-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/multilayer_fdr-1400.webp"></source> <img src="/assets/img/multilayer_fdr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Hypotheses across partitions" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This figure was taken from Ramdas et al., 2019 and visualizes various partitions and groupings of hypotheses </div> <h2 id="generating-data-and-e-values">Generating data and e-values</h2> <p>E-values are heavily context-dependent. Depending on the analyst’s level of familiarity with the setting, this may be good or bad. For this simulation, we adapt a modified version of the example in Section (8) in <a href="https://academic.oup.com/jrsssb/article/84/3/822/7056146" rel="external nofollow noopener" target="_blank">Wang &amp; Ramdas, 2022</a>. In essence, the authors propose an e-value approach to detecting cryptocurrencies with positive expected return. There are \(K\) different cryptocurrencies (“coins”) over \(T\) periods of time.</p> <p>We are modifying the authors’ example as follows: Since we don’t have access to their data, we consider two distinct data-generating processes to obtain our year-to-year stock rate of change. First, we consider a scenario where all values are sampled i.i.d. from a truncated normal distribution, \(TN(\mu = 1,\sigma = 1;\text{trunc-null},\infty)\). This will yield the year-to-year percentage positive change in the price of stock of a specific cryptocurrency, e.g. \(X_{i,j} &gt; 1\) if a coin’s value had increased. Second, we are considering a sequential dependence scenario inspired by the authors’ example. Rather than sampling data i.i.d. from a truncated normal with mean 1, we introduce sequential dependence by letting a previous realization become the next period’s mean.</p> <p>\(\text{Initialize} X_{k,t_0} = 1. \text{Then,}\) <br> \(X_{k,1} \sim TN(\mu = X_{k,t_0}, \sigma = 1; \text{trunc-null}, \infty),\) \(X_{k,2} \sim TN(\mu = X_{k,1}, \sigma = 1; \text{trunc-null}, \infty),\, \ldots,\,\) \(X_{k,T} \sim TN(\mu = X_{k,T-1}, \sigma = 1; \text{trunc-null}, \infty)\)</p> <p>In the i.i.d scenario, we will calculate e-values as the cumulative product of \(X_{ij}\):</p> \[E_{k,t} = \prod_{j=1}^{t} (X_{k,j}), t=1,...,T.\] <p>This is equivalent to the authors’ derivation of e-values, \(E_{k,t} = \prod_{j=1}^{t} (1 - \lambda + \lambda X_{k,j}), t=1,...,T.\), when setting the investment parameter \(\lambda = 1\).</p> <pre><code class="language-{r}"># Inputs
nrow = 4; ncol = 5
trunc_null = 0; trunc_signal = 4

# Matrix shell
X_iid &lt;- matrix(NA, nrow = nrow, ncol = ncol)

# Sampling Loop
for (k in 1:nrow) {
  for (t in 1:ncol) {
    if (k %% 2 == 0){
      # Sample a signal from truncated normal distribution
      X_iid[k, t] &lt;- rtruncnorm(1, a = trunc_signal, mean = 1, sd = 1)
    } else{
      # Sample a null from truncated normal distribution
      X_iid[k, t] &lt;- rtruncnorm(1, a = trunc_null, mean = 1, sd = 1)
    }
    
  }
}

# Print
X_iid
</code></pre> <pre><code class="language-{r}"># Inputs
nrow = 4; ncol = 5
trunc_null = 0; trunc_signal = 4

# Matrix shell
X_dep &lt;- matrix(NA, nrow = nrow, ncol = ncol)

# Sampling Loop
for (k in 1:nrow) {
  # Initialize the mean for the current row
  row_mean &lt;- 1
  
  for (t in 1:ncol) {
    if (k %% 2 == 0){
      # Sample from a truncated normal distribution with lower bound of 0
      X_dep[k, t] &lt;- rtruncnorm(1, a = trunc_signal, mean = row_mean, sd = 1)
    } else {
      # Sample from a truncated normal distribution with lower bound of 0
      X_dep[k, t] &lt;- rtruncnorm(1, a = trunc_null, mean = row_mean, sd = 1)
    }
    
    # Update the mean for the next sample in the same row
    row_mean &lt;- X_dep[k, t]
  }
}

# Print
X_dep
</code></pre> <p>The matrices <code class="language-plaintext highlighter-rouge">X_iid</code> and <code class="language-plaintext highlighter-rouge">X_dep</code> both represent the year-to-year percentage positive change in the price of stock of a specific cryptocurrency. However, <code class="language-plaintext highlighter-rouge">X_dep</code> represents sequentially dependent data. Note that we have also introduced signals into the matrices by varying the truncation cutoff. For even coins, i.e. <code class="language-plaintext highlighter-rouge">k %% 2 == 0</code>, our realizations of year-to-year growth are significantly higher than for the other coins, symbolizing a signal.</p> \[E_{k,t} = \prod_{j=1}^{t} (X_{k,j}), \quad t=1,...,T.\] <pre><code class="language-{r}"># E-values dependent
E_dep &lt;- X_dep

# E-values iid
E_iid &lt;- matrix(NA, nrow = nrow, ncol = ncol)

# Calculate E_iid matrix via cumulative product
for (i in 1:nrow) {
  for (j in 1:ncol) {
      E_iid[i, j] &lt;- prod(X_iid[i, 1:j])
  }}
    

# Print
E_iid
</code></pre> <p>Since the <code class="language-plaintext highlighter-rouge">X_dep</code> entries are already sequentially dependent, we consider them as e-values themselves, on grounds of the dependence. Our entries in the <code class="language-plaintext highlighter-rouge">X_iid</code> matrix are converted to e-values using the cumulative product, as outlined previously. The purpose of these different approaches is to create dependent e-values in two different ways.</p> <p>We have now constructed our matrix of e-values, both for the iid (<code class="language-plaintext highlighter-rouge">E_iid</code>) and the sequential dependence case (<code class="language-plaintext highlighter-rouge">E_dep</code>). Immediately, we can see that the <code class="language-plaintext highlighter-rouge">E_iid</code> values explode with time. There is significant difference between earlier and later time periods. This makes sense since we derived the e-values using the cumulative product. In contrast, the <code class="language-plaintext highlighter-rouge">E_dep</code> values are relatively homogeneous across columns. There are visible differences across rows, owing to the truncation specific to signals and nulls.</p> <p>Both ways of constructing e-values have their pros and cons. The <code class="language-plaintext highlighter-rouge">E_iid</code> e-values that were derived are very sensitive to larger initial quantities. This could be especially valuable to an analyst only interested in controlling FDR on the group-level, i.e. the coin (more on that in the section: <code class="language-plaintext highlighter-rouge">Group-specific p-values</code>). In contrast, taking the <code class="language-plaintext highlighter-rouge">E_dep</code> e-values at face value may be valuable if an analyst does care about controlling FDR over multiple partitions, e.g., time. The <code class="language-plaintext highlighter-rouge">E_iid</code> e-values may be less fit for this finer analysis since the exploding values in later time periods dillute the accurate encoding of information. This discussion illustrates well how important it is to carefully weigh the pros and cons of using e-values vs. p-values.</p> <h2 id="transforming-e-values-to-p-values">Transforming e-values to p-values</h2> <p>A key strength of e-values is their flexibility, i.e. we have many ways to create e-values, we may combine them, and there are multiple ways to transform e-values to p-values. Generally speaking, we can define a transformation of e-values to p-values as a e-to-p calibrator, i.e.</p> <p>Let \(f : [0, \infty) \rightarrow [0, 1]\) be a decreasing function. It is an e-to-p calibrator if, for any e-variable E, \(f(E)\) is a p-variable (i.e., f transforms e-values to p-values).</p> <p>Although this flexibility is great, it comes with the danger of losing valuable information if this calibration is not done in a way that matches the context of the e-values. In the following, we contrast two ways to convert e-values to p-values and illustrate their respective advantages and drawbacks. The conversion is as follows (see Remark 1 in Wang &amp; Ramdas, 2021):</p> \[p_{k,t} = \frac{1}{e_{k,t}}\] <pre><code class="language-{r}"># Calculate idiosyncratic p-values
P_iid &lt;- matrix(1/E_iid, nrow = nrow, ncol = ncol)
P_dep &lt;- matrix(1/E_dep, nrow = nrow, ncol = ncol)

# Print
P_iid
P_dep

# Truncate values greater than 1
P_iid[P_iid &gt; 1] &lt;- 1
P_dep[P_dep &gt; 1] &lt;- 1

# Print
P_iid
P_dep

# Unlist
Pvec_iid &lt;- as.vector(P_iid)
Pvec_dep &lt;- as.vector(P_dep)
</code></pre> <p>Looking at the <code class="language-plaintext highlighter-rouge">P_iid</code> matrix, we can immediately see a problem with this conversion. If an e-value is less than 1, it yields a p-value over ‘1’, thus yielding invalid probabilities. The solution is to truncate values that exceed 1 at 1, which does give us valid p-values, but we lose information. Intuitively, this could mean that this conversion is better fit for situations where e-values tend to be larger.</p> <h2 id="group-specific-p-values">Group-specific p-values</h2> <p>An interesting application of e-values in this setting–in line with the authors’ example–is to reduce the analysis back to the group-setting, similar to the authors’ goal. Taking inspiration from the authors, we can define a group-specific p-value as:</p> \[P_{k,j} := \max (E_{k,i})^{-1}\] <p>Although we lose a layer of information, i.e. we can no longer partition across additional groups (which we will consider later in the <code class="language-plaintext highlighter-rouge">p-filter</code> example), we can get good insight into each group hypothesis. To continue the previous arguement, here the exploding e-values are less of an issue because we are only consider the maximum row-wise e-value. We care less about the between-column heterogeneity of e-values and only hope to make valid inference on the coin-level. Note that because we are choosing the maximum e-value, we are also minimizing the risk that our raw p-value exceeds 1. This is a hint that this procedure might be a good fit for this scenario. Alternatively, we could combine the e-values by obtaining the average which is valid under dependence. In an iid scenario, we could also add e-values.</p> <p>We think this e-value design coupled with group-wise inference could be relevant to scenarios where signals of varying strength are present. The exploding nature of the cumulative product would, given enough iterations, also magnify signals of lesser magnitude. This could be a great fit in a scenario where the analyst puts a lot of emphasis on finding weaker signals, i.e. a geneticist interested in locating loci associated with a certain disease, even those that have less association (Think: Genome-wide association studies).</p> <p>We can see that the p-values are indeed lower for the signal (recall that even row indices are classified as signals) coins. The differences in p-values are far more pronounced in the <code class="language-plaintext highlighter-rouge">Pg_iid</code> vector, owing to the large maximum e-values. The group-wise p-values for the <code class="language-plaintext highlighter-rouge">Pg_dep</code> case are high, but do not vary as drastically between nulls and signals.</p> <h2 id="an-e-filter-approach">An <code class="language-plaintext highlighter-rouge">e-filter</code> approach</h2> <p>Although the previous finding is promising in terms of conducting inference under dependence, what happens if we are interested controlling for FDR beyond the group-level? That question is why we will explore the <code class="language-plaintext highlighter-rouge">pfilter</code> function. The <code class="language-plaintext highlighter-rouge">p-filter</code> is designed to guarantee FDR control across multiple partitions of hypotheses. Our endeavor in exploring the <code class="language-plaintext highlighter-rouge">p-filter</code> in an e-value framework is to reformulate the computational task of running <code class="language-plaintext highlighter-rouge">e-filter</code> into a <code class="language-plaintext highlighter-rouge">p-filter</code> task so that we can use the existing code.</p> <pre><code class="language-{r}">pfilter = function(P,alphas,groups){
	# P in [0,1]^n = vector of p-values
	# alphas in [0,1]^M = vector of target FDR levels
	# groups is a n-by-M matrix; 
	#	groups[i,m] = which group does P[i] belong to,
	#		for the m-th grouping
	
	n = length(P)
	M = length(alphas)
	G = apply(groups,2,max) # G[m] = # groups, for grouping m
	
	
	Simes = list()
	for(m in 1:M){
		Simes[[m]]=rep(0,G[m])
		for(g in 1:G[m]){
			group = which(groups[,m]==g)
			Simes[[m]][g]=min(sort(P[group])*length(group)/(1:length(group)))
		}
	}
	
		
	# initialize
	thresh = alphas
	Sh = 1:n
	for(m in 1:M){
		pass_Simes_m = which(is.element(groups[,m],which(Simes[[m]]&lt;=thresh[m])))
		Sh = intersect(Sh,pass_Simes_m)
	}
	done = FALSE


	while(!done){
		thresh_old = thresh
		for(m in 1:M){
			# which groups, for the m-th grouping, 
			#	have any potential discoveries?
			Shm = sort(unique(groups[Sh,m]))

			# run BH on Simes[[m]], constraining to Shm
			Pvals_m = rep(1.01,G[m]); # &gt;1 for groups not in Dm
			Pvals_m[Shm] = Simes[[m]][Shm]
			khatm = max(0,which(sort(Pvals_m)&lt;=(1:G[m])/G[m]*alphas[m]))
			thresh[m] = khatm/G[m]*alphas[m]
			Sh = intersect(Sh,
				which(is.element(groups[,m],which(Pvals_m&lt;=thresh[m]))))
		}
		if(all(thresh_old==thresh)){done = TRUE}
	}
	
	Sh_temp = Sh;
	Sh = rep(0,n); Sh[Sh_temp] = 1
	Sh

}
</code></pre> <p>Next, we can specify at what levels we want to control overall and group-level FDR, respectively. To control overall FDR, the first column of “groups” places each p-value into its own group to control group-level FDR, the second column of “groups” assigns each p-value to its group (group 1, 2, 3, or 4). Finally, we can take a look at the discoveries. A “1” indicates that the p-value was selected (identified as a likely true signal)</p> <p>First, let us run this <code class="language-plaintext highlighter-rouge">p-filter</code> procedure on our i.i.d. p-values.</p> <pre><code class="language-{r}"># Inputs
fdr_overall = 0.2; fdr_gr = 0.3

# Levels of FDR control
alphas = c(fdr_overall, fdr_gr)

# Specify groups
groups = cbind(1:length(Pvec_iid), 
               c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4))

# Find discoveries
Discoveries1_iid = pfilter(Pvec_iid,alphas,groups)

# Print
Discoveries1_iid
</code></pre> <p>We can see that the discoveries in the iid case are concentrated in the later time periods, but do accurately correspond with signals and nulls. An issue here is that the earlier signals are not identified. This is because the earlier e-values have not yet “exploded.”</p> <pre><code class="language-{r}"># Inputs
fdr_overall = 0.2; fdr_gr = 0.3

# Levels of FDR control
alphas = c(fdr_overall, fdr_gr)

# Specify groups
groups = cbind(1:length(Pvec_dep), 
               c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4))

# Find discoveries
Discoveries1_dep = pfilter(Pvec_dep,alphas,groups)

# Print
Discoveries1_dep
</code></pre> <p>In the <code class="language-plaintext highlighter-rouge">Pvec_dep</code> case, we see that we have no discoveries at the specified levels of <code class="language-plaintext highlighter-rouge">alpha</code>. As we saw before, this is because (i) the p-values are already very high and (ii) the additional layer of FDR control (group-specific and overall) takes its toll. Alternatively, we could adjust our <code class="language-plaintext highlighter-rouge">alpha</code> values. However, it is also important to note that our simulation sample is very small and therefore the sequential dependence relationship has little room to “unfold”. In a real-world scenario, the sequential dependence relationship would likely become more pronounced over more time periods.</p> <p>All in all, this simulation is an example of how difficult it is to conduct valid inference under dependence. P-values come with a precise probabilistic meaning, but fail under dependence. E-values are heavily context-dependent and can be harmful in the wrong application, but allow for flexibility under dependence. Future research in the replicability and use of of e-values under dependence sounds very intriguing to us after conducting this project.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Daniel C. Posmik. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>